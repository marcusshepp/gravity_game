{"cells":[{"metadata":{"collapsed":false,"trusted":false},"cell_type":"code","source":"class NeuralNetwork(object):\n    \"\"\"  \n    Hold all layers together and propogate values through the net.\n    \"\"\"\n    def __init__(self, data):\n        \"\"\"\n        Hold data ie weights thresholds and input.\n        also holds neurons for each layer\n        \"\"\"\n        # create layers\n        self.input_layer = data[\"num_input_nodes\"]\n        self.hidden_layer = data[\"num_hidden_nodes\"]\n        self.output_layer = data[\"num_output_nodes\"]\n        # inputs\n        self.inputs = data[\"inputs\"]\n        # weights\n        self.first_weights = data[\"first_weights\"]\n        self.second_weights = data[\"second_weights\"]\n        self.third_weights = data[\"third_weights\"]\n        # thresholds\n        self.first_thresholds = data[\"first_thresholds\"]\n        self.second_thresholds = data[\"second_thresholds\"]\n        self.third_thresholds = data[\"third_thresholds\"]\n    \n    def __neural_output(self, weights, inputs, threshold):\n        \"\"\"\n        in: weights, inputs, threshold\n        out: 1 or 0\n        \n        if the (sum of weights) x (sum of inputs)\n        is greater than my threshold\n        output 1\n        else 0\n        \"\"\"\n        length = len(inputs)\n        activation = 0\n        output = 0\n        for i in range(length):\n            activation += weights[i] * inputs[i]\n        if activation > threshold:\n            output = 1\n        return output\n    \n    def __layer_out(self, weights, inputs, thresholds):\n        \"\"\"  \n        for all input & weights, compute each output from each neuron.\n        \"\"\"\n        outs = []\n        # number of thresholds = number of output bits\n        for threshold in thresholds:\n            outs.append(\n                self.__neural_output(weights,\n                              inputs,  \n                              threshold))\n        return outs\n    \n    def one_out(self):\n        \"\"\"\n        return bits for input layer.\n        \"\"\"\n        return self.__layer_out(self.first_weights, \n                              self.inputs, \n                              self.first_thresholds)\n    \n    def hidden_layer_out(self):\n        \"\"\"\n        return bits for hidden layer.\n        \"\"\"\n        return self.__layer_out(self.second_weights, \n                              self.one_out(), \n                              self.second_thresholds)\n    \n    def output_layer_out(self):\n        \"\"\"\n        return bits for ouput layer.\n        \"\"\"\n        return self.__layer_out(self.third_weights, \n                              self.hidden_layer_out(), \n                              self.third_thresholds)\n    \n    def out(self):\n        \"\"\"\n        for show\n        \"\"\"\n        return self.output_layer_out()","execution_count":220,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"planets = [[200,100,50,50,1],[400,100,50,50,1],[600,100,50,50,1]]\n\ndef to_bin(data, length):\n    return bin(int(data))[2:].zfill(length)\n\ndef planet_to_bin_rep(planets):\n#     print planets\n    planet_one = [to_bin(planets[0][0], 10),\n                  to_bin(planets[0][1], 10),\n                  to_bin(planets[0][4], 3)]\n    planet_two = [to_bin(planets[1][0], 10),\n                  to_bin(planets[1][1], 10),\n                  to_bin(planets[1][4], 3)]\n    planet_three = [to_bin(planets[2][0], 10),\n                    to_bin(planets[2][1], 10),\n                    to_bin(planets[2][4], 3)]\n    return planet_one, planet_two, planet_three\n\ndef full_input(l):\n    value = \"\"\n    for i in l:\n        for d in i:\n            value += d\n    return [int(i) for i in value]","execution_count":222,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":"def nn_info(inp,inl,hid,out):\n    \"\"\"\n    given hidden input and out\n    gives number of weights0 + weights1 + weights2 + thresholds needed\n    \"\"\"\n    w0 = inp * inl\n    w1 = inl * hid\n    w2 = hid * out\n    p = lambda x, y, z: \"Weights from {0} to {1}: {2}\\n\".format(x, y, z)\n    print p(\"input\", \"layer one\", str(w0))\n    print p(\"layer one\", \"layer two\", str(w1))\n    print p(\"layer two\", \"layer three\", str(w2))\n    print \"{0} thresholds are needed. \\n\".format(inp+hid+out)\n    print \"total: \",w0 + w1 + w2 + inp + inl + hid + out, \"\\n\"\n    return w0, w1, w2, inp+hid+out\n\nprint nn_info(69, 9, 5, 20)","execution_count":13,"outputs":[{"output_type":"stream","text":"Weights from input to layer one: 621\n\nWeights from layer one to layer two: 45\n\nWeights from layer two to layer three: 100\n\n94 thresholds are needed. \n\ntotal:  869 \n\n(621, 45, 100, 94)\n","name":"stdout"}]},{"metadata":{"slideshow":{"slide_type":"notes"}},"cell_type":"markdown","source":"# Genetic Algorithm\n\n### in: none\n### out: weights, thresholds\n\ncreate random chromes\n\nfor each chrome do\n\n    create new nn\n    \n    run nn\n    \n    compare output to desired output\n    \n    assign fitness\n    \n    select part\n    \n    cross\n    \n    mutate\n    \ncreate new pop\n"},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":"import random as r\n\ndef init_population(pop_size):\n    population = []\n    for _ in xrange(pop_size):\n        chrome = []\n        # size of chrome\n        # total number of weights and thresholds\n        for i in range(869):\n            chrome.append(r.randrange(-255, 255))\n        population.append(chrome)\n    return population\n\n","execution_count":11,"outputs":[{"output_type":"stream","text":"[[176, -116, -54, -246, -157, -105, -206, -19, -185, 151, -9, 65, 110, 62, -2, -62, 210, -10, 97, 210, 37, 186, -252, -221, 108, 195, -86, 67, 151, 5, 245, 48, -102, 46, 216, -50, 91, 63, -184, -148, 38, -253, -164, -36, -107, 47, 63, 21, 83, 77, 138, -218, 138, 147, 102, -139, -139, 72, 132, 206, 157, -241, -138, -15, -200, 127, 32, 202, 104, 51, 40, 14, -208, 51, 48, -128, -35, -123, 134, 110, -220, 71, -125, -184, -147, -176, 240, 135, -117, 239, -39, -9, -133, 37, -160, -138, -89, -224, -176, 134, -150, -88, 39, 196, 81, 170, 24, -156, 221, 123, 215, 149, 66, -170, -79, 21, -192, -149, -242, -196, 19, -83, 218, -252, 240, -189, 219, 177, 34, 42, -92, -132, 82, -109, 96, 107, -150, 178, 105, 6, 89, -227, -115, -2, 215, -251, 127, 41, 27, -196, 72, 115, -20, 203, -119, -117, -237, -88, -171, 163, -213, 201, -245, -76, 64, -128, 116, -242, 4, 154, -19, -66, -58, -185, 110, 101, 44, -165, -222, -57, 121, -209, -120, -193, 22, -56, -215, 6, 190, 130, -175, -51, -241, 90, 100, 29, 123, 67, -69, -246, 104, -233, -4, 11, -228, 211, 218, 98, 98, -20, -48, 184, -55, 63, 13, -225, 131, 53, -157, -253, -163, 22, 236, 54, -188, -122, -105, 76, -84, 119, -19, -218, -111, -116, 204, 245, -180, -40, 105, 136, -215, -112, 160, 223, -189, 183, -246, 226, -30, -4, -167, -72, 24, -3, -64, -154, 100, -126, 246, -237], [215, 183, -100, -97, -13, -118, -128, -126, -49, 125, -8, 180, 67, 2, -129, -43, -73, -136, -211, 213, -202, 211, 223, -96, 50, 40, 43, -97, -203, -214, 15, 3, 72, -72, 180, -90, -99, -113, -109, -247, 219, -72, 243, 11, 123, -80, 23, 125, 1, 228, -165, -211, -171, -14, -198, -250, 33, -213, -123, -189, -248, -183, 130, 38, 150, -224, -89, 33, 29, -89, -76, 9, 27, 136, -45, -138, 67, 122, 115, -68, -195, -132, -143, 209, 59, 176, 185, 70, -9, -253, 46, 235, 155, 173, -7, 1, 13, -132, 19, 116, -52, -17, 68, -104, -105, 111, -58, 122, 33, -216, -99, -20, -103, 240, -95, -112, -33, 88, 74, -198, 88, -144, 120, 182, 130, -82, 7, -210, -12, 244, 177, -165, 5, -223, -87, -242, -41, 104, 9, 251, 212, 82, 43, -83, 118, 131, -228, 133, -12, 13, -176, 130, 177, -91, -202, 14, 35, 178, 4, -147, -63, -190, -57, -159, 84, -115, -235, -99, 190, -180, 174, 62, 168, -65, 133, 54, 66, -12, 58, -233, -203, -33, 221, -183, 220, -75, -137, 22, -107, 239, -240, -65, -67, 141, -230, -117, 243, -103, -29, -157, 69, -227, -76, 211, -64, -13, -211, -48, 229, 23, -137, 130, -54, 194, -15, -155, -155, -156, -195, 19, -158, 34, -10, 104, 132, -128, -74, 176, -110, -76, 126, -25, -145, 112, 44, -54, -173, 50, 235, 55, 102, -60, 16, 70, 161, 21, 226, 153, 223, 39, 244, -249, -214, 173, -51, 61, 68, 95, 144, -9]]\n","name":"stdout"}]},{"metadata":{"collapsed":false,"trusted":false},"cell_type":"code","source":"import random\n\ndata = {\n    \"num_input_nodes\": 9,\n    \"num_hidden_nodes\": 5,\n    \"num_output_nodes\": 20,\n    \"inputs\": full_input(planet_to_bin_rep(planets))} # y x m\n    # len of from * len of to\ndata[\"first_weights\"] = []# 69 * 9\ndata[\"second_weights\"] = [] # 9 * 5\ndata[\"third_weights\"] = [] # 5 * 20\n    # len of layer\ndata[\"first_thresholds\"] = []\ndata[\"second_thresholds\"] = []  \ndata[\"third_thresholds\"] = []\n\nnn = NeuralNetwork(data)\nprint nn.out()","execution_count":221,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python2","display_name":"Python 2","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython2","version":"2.7.10","file_extension":".py","codemirror_mode":{"version":2,"name":"ipython"}}},"nbformat":4,"nbformat_minor":0}